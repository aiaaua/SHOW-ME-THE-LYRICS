{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras.collbacks'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-32914302af0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollbacks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLambdaCallback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_utils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mget_file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras.collbacks'"
     ]
    }
   ],
   "source": [
    "from keras.collbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'io' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-d9eead0949c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lyric.txt'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'io' is not defined"
     ]
    }
   ],
   "source": [
    "path = 'data.csv'\n",
    "\n",
    "with io.open(path, encoding = 'utf-8') as f :\n",
    "    corpus = f.read().lower()\n",
    "    \n",
    "corpus = re.sub('\\n', ' ', corpus)\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1057"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_length = len(corpus)\n",
    "corpus_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = sorted(list(set(corpus)))\n",
    "total_words = len(words)\n",
    "total_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '3': 1, '4': 2, 'a': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'k': 11, 'l': 12, 'm': 13, 'n': 14, 'o': 15, 'p': 16, 'r': 17, 's': 18, 't': 19, 'u': 20, 'w': 21, 'x': 22, 'y': 23, '가': 24, '간': 25, '강': 26, '같': 27, '갚': 28, '개': 29, '거': 30, '건': 31, '것': 32, '게': 33, '겨': 34, '격': 35, '경': 36, '계': 37, '고': 38, '공': 39, '과': 40, '관': 41, '구': 42, '권': 43, '그': 44, '근': 45, '기': 46, '긴': 47, '까': 48, '깐': 49, '깽': 50, '꼭': 51, '꾼': 52, '끈': 53, '끝': 54, '나': 55, '난': 56, '날': 57, '남': 58, '내': 59, '냄': 60, '냐': 61, '너': 62, '넌': 63, '널': 64, '넘': 65, '네': 66, '녜': 67, '놈': 68, '누': 69, '느': 70, '는': 71, '니': 72, '다': 73, '닥': 74, '단': 75, '달': 76, '담': 77, '대': 78, '댈': 79, '더': 80, '덕': 81, '데': 82, '도': 83, '독': 84, '돈': 85, '동': 86, '돼': 87, '되': 88, '든': 89, '듣': 90, '들': 91, '등': 92, '딴': 93, '때': 94, '떤': 95, '똑': 96, '라': 97, '란': 98, '람': 99, '랑': 100, '래': 101, '랩': 102, '럭': 103, '럼': 104, '럽': 105, '레': 106, '려': 107, '력': 108, '로': 109, '론': 110, '른': 111, '를': 112, '리': 113, '린': 114, '마': 115, '만': 116, '많': 117, '말': 118, '망': 119, '맞': 120, '매': 121, '맨': 122, '맴': 123, '머': 124, '면': 125, '모': 126, '목': 127, '못': 128, '무': 129, '물': 130, '믿': 131, '바': 132, '박': 133, '반': 134, '발': 135, '밟': 136, '밥': 137, '뱀': 138, '뱅': 139, '번': 140, '벌': 141, '변': 142, '보': 143, '복': 144, '봐': 145, '부': 146, '불': 147, '비': 148, '빨': 149, '빵': 150, '사': 151, '산': 152, '상': 153, '새': 154, '색': 155, '생': 156, '서': 157, '선': 158, '성': 159, '세': 160, '소': 161, '솔': 162, '술': 163, '숨': 164, '쉬': 165, '스': 166, '슬': 167, '승': 168, '시': 169, '식': 170, '신': 171, '실': 172, '싸': 173, '아': 174, '악': 175, '알': 176, '앞': 177, '애': 178, '야': 179, '어': 180, '언': 181, '업': 182, '없': 183, '에': 184, '여': 185, '연': 186, '영': 187, '예': 188, '오': 189, '와': 190, '완': 191, '왕': 192, '왜': 193, '외': 194, '요': 195, '운': 196, '울': 197, '웃': 198, '원': 199, '위': 200, '윤': 201, '으': 202, '은': 203, '음': 204, '의': 205, '이': 206, '익': 207, '인': 208, '일': 209, '임': 210, '입': 211, '자': 212, '작': 213, '잔': 214, '잠': 215, '잣': 216, '장': 217, '잽': 218, '쟁': 219, '저': 220, '적': 221, '전': 222, '절': 223, '정': 224, '져': 225, '졌': 226, '족': 227, '졸': 228, '좀': 229, '좆': 230, '죽': 231, '즘': 232, '지': 233, '직': 234, '진': 235, '짐': 236, '집': 237, '차': 238, '착': 239, '찬': 240, '찰': 241, '참': 242, '처': 243, '척': 244, '체': 245, '취': 246, '치': 247, '컬': 248, '큰': 249, '탈': 250, '탓': 251, '탕': 252, '태': 253, '탱': 254, '투': 255, '파': 256, '퍼': 257, '하': 258, '한': 259, '할': 260, '함': 261, '항': 262, '해': 263, '행': 264, '허': 265, '형': 266, '혹': 267, '혼': 268, '회': 269, '후': 270, '희': 271, '히': 272}\n",
      "{0: ' ', 1: '3', 2: '4', 3: 'a', 4: 'c', 5: 'd', 6: 'e', 7: 'f', 8: 'g', 9: 'h', 10: 'i', 11: 'k', 12: 'l', 13: 'm', 14: 'n', 15: 'o', 16: 'p', 17: 'r', 18: 's', 19: 't', 20: 'u', 21: 'w', 22: 'x', 23: 'y', 24: '가', 25: '간', 26: '강', 27: '같', 28: '갚', 29: '개', 30: '거', 31: '건', 32: '것', 33: '게', 34: '겨', 35: '격', 36: '경', 37: '계', 38: '고', 39: '공', 40: '과', 41: '관', 42: '구', 43: '권', 44: '그', 45: '근', 46: '기', 47: '긴', 48: '까', 49: '깐', 50: '깽', 51: '꼭', 52: '꾼', 53: '끈', 54: '끝', 55: '나', 56: '난', 57: '날', 58: '남', 59: '내', 60: '냄', 61: '냐', 62: '너', 63: '넌', 64: '널', 65: '넘', 66: '네', 67: '녜', 68: '놈', 69: '누', 70: '느', 71: '는', 72: '니', 73: '다', 74: '닥', 75: '단', 76: '달', 77: '담', 78: '대', 79: '댈', 80: '더', 81: '덕', 82: '데', 83: '도', 84: '독', 85: '돈', 86: '동', 87: '돼', 88: '되', 89: '든', 90: '듣', 91: '들', 92: '등', 93: '딴', 94: '때', 95: '떤', 96: '똑', 97: '라', 98: '란', 99: '람', 100: '랑', 101: '래', 102: '랩', 103: '럭', 104: '럼', 105: '럽', 106: '레', 107: '려', 108: '력', 109: '로', 110: '론', 111: '른', 112: '를', 113: '리', 114: '린', 115: '마', 116: '만', 117: '많', 118: '말', 119: '망', 120: '맞', 121: '매', 122: '맨', 123: '맴', 124: '머', 125: '면', 126: '모', 127: '목', 128: '못', 129: '무', 130: '물', 131: '믿', 132: '바', 133: '박', 134: '반', 135: '발', 136: '밟', 137: '밥', 138: '뱀', 139: '뱅', 140: '번', 141: '벌', 142: '변', 143: '보', 144: '복', 145: '봐', 146: '부', 147: '불', 148: '비', 149: '빨', 150: '빵', 151: '사', 152: '산', 153: '상', 154: '새', 155: '색', 156: '생', 157: '서', 158: '선', 159: '성', 160: '세', 161: '소', 162: '솔', 163: '술', 164: '숨', 165: '쉬', 166: '스', 167: '슬', 168: '승', 169: '시', 170: '식', 171: '신', 172: '실', 173: '싸', 174: '아', 175: '악', 176: '알', 177: '앞', 178: '애', 179: '야', 180: '어', 181: '언', 182: '업', 183: '없', 184: '에', 185: '여', 186: '연', 187: '영', 188: '예', 189: '오', 190: '와', 191: '완', 192: '왕', 193: '왜', 194: '외', 195: '요', 196: '운', 197: '울', 198: '웃', 199: '원', 200: '위', 201: '윤', 202: '으', 203: '은', 204: '음', 205: '의', 206: '이', 207: '익', 208: '인', 209: '일', 210: '임', 211: '입', 212: '자', 213: '작', 214: '잔', 215: '잠', 216: '잣', 217: '장', 218: '잽', 219: '쟁', 220: '저', 221: '적', 222: '전', 223: '절', 224: '정', 225: '져', 226: '졌', 227: '족', 228: '졸', 229: '좀', 230: '좆', 231: '죽', 232: '즘', 233: '지', 234: '직', 235: '진', 236: '짐', 237: '집', 238: '차', 239: '착', 240: '찬', 241: '찰', 242: '참', 243: '처', 244: '척', 245: '체', 246: '취', 247: '치', 248: '컬', 249: '큰', 250: '탈', 251: '탓', 252: '탕', 253: '태', 254: '탱', 255: '투', 256: '파', 257: '퍼', 258: '하', 259: '한', 260: '할', 261: '함', 262: '항', 263: '해', 264: '행', 265: '허', 266: '형', 267: '혹', 268: '혼', 269: '회', 270: '후', 271: '희', 272: '히'}\n"
     ]
    }
   ],
   "source": [
    "words_indices = dict((c,i) for i, c in enumerate(words))\n",
    "indices_words = dict((i,c) for i, c in enumerate(words))\n",
    "\n",
    "print(words_indices)\n",
    "print(indices_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences :  339\n"
     ]
    }
   ],
   "source": [
    "max_length = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "\n",
    "for i in range(0, len(corpus) - max_length, step) :\n",
    "    sentences.append(corpus[i:i+max_length])\n",
    "    next_chars.append(corpus[i+max_length])\n",
    "\n",
    "print('nb sequences : ', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.zeros((len(sentences), max_length, len(words)), dtype = np.bool)\n",
    "y = np.zeros((len(sentences), len(words)), dtype = np.bool)\n",
    "\n",
    "for i, sentence in enumerate(sentences) :\n",
    "    for j, word in enumerate(sentence) :\n",
    "        x[i, j, words_indices[word]] = 1\n",
    "    y[i, words_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(1024, input_shape = (max_length, len(words))))\n",
    "model.add(Dense(len(words), activation = 'softmax'))\n",
    "\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = RMSprop(lr = 0.001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature = 1.0) :\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.ramdon.multinomila(1, preds, 1)\n",
    "    return np.argmax(probas)\n",
    "\n",
    "def on_epoch_end(epoch, _) :\n",
    "    start_index = random.randint(0, len(chrpus) - max_length -1)\n",
    "    generated = ''\n",
    "    sentence = corpus[start_index : start_index + max_length]\n",
    "    generated += sentence\n",
    "    sys.stdout.write(generated)\n",
    "    \n",
    "    for i in range(400) :\n",
    "        x_pred[0, t, word_indices[word]] = 1\n",
    "        next_index = sample(preds, 0.5)\n",
    "        next_word = indices_word[next_index]\n",
    "        \n",
    "        generated += next_word\n",
    "        sentence = sentence[1:] + next_word\n",
    "        \n",
    "        sys.stdout.write(next_word)\n",
    "        sys,stdout.flush()\n",
    "    print()\n",
    "    \n",
    "print_callback = LambdaCallback(on_epoch_end = on_epoch_end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x, y, batch_size = 128, epochs = 60, callbacks = [print_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
